{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Selecting Best Model for Given Data Set using Multiple Regression Techniques\n",
    "# Name: Umar Ahsan\n",
    "# SID: 200 353 718\n",
    "# ENEL 890AK Course Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement: The main goal of this project is to deploy currently \n",
    "# available regression techniques on selected data set ( Housing Data) to \n",
    "# generate the most accurate model for that data in order to predict price of any house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps:\n",
    "--- Implement Lasso regression using graphlab linear_regression function with different L1 penalty.\n",
    "--- Choose best L1 penalty using validation set.\n",
    "--- Implement Ridge regression using graphlab linear_regression function with different L2 penalty.\n",
    "--- Choose best L2 penalty using validation set.\n",
    "--- Implement ElasticNet regression using graphlab linear_regression function with different L1 and L2 penalty.\n",
    "--- Choose best L1 and L2 penalty using validation set.\n",
    "--- Compare performance of all three models on test set through RSS calculation\n",
    "--- Add features in the data set that are generated from existing features and add them to the data set.\n",
    "--- Repeat all three regression techniques on the new data set and compare the performance of model using RSS.\n",
    "--- Compare the results of new data set models with original data set model using RSS values.\n",
    "--- The model with minimum RSS will be the best fited model among these three regression techniques for Housing Data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version of GraphLab Create (v2.1) is available! Your current version is v1.10.1.\n",
      "\n",
      "You can use pip to upgrade the graphlab-create package. For more information see https://dato.com/products/create/upgrade.\n"
     ]
    }
   ],
   "source": [
    "# Import Graphlab library into Notebook\n",
    "import graphlab\n",
    "# Import numpy for vector manipulation \n",
    "import numpy as np\n",
    "# Import pyplot from matplotlib in order to plot values on graph\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to ahsan20u@uregina.ca and will expire on June 23, 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v1.10.1 started. Logging: C:\\Users\\Umar\\AppData\\Local\\Temp\\graphlab_server_1470618874.log.0\n"
     ]
    }
   ],
   "source": [
    "# Loading data set and storing it into sales_data\n",
    "sales_data = graphlab.SFrame('kc_house_data.gl/kc_house_data.gl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The next step is to divide the data set into training and testing subset.\n",
    "# After reading few articles, it is concluded that generally the best split between training and test subset is 80/20 i.e. \n",
    "# 90 % data should be training while 10 % should be testing.\n",
    "(training_and_validation_data, testing_data) = sales_data.random_split(.9,seed=1) # initial training/test split as discussed above.\n",
    "# Here, seed=1 is used that will act as a parameter to generate random split for the data set.\n",
    "# Since we will be using cross validation therefore we donot need to split 'training_and_validation_data' into 'training' and\n",
    "# 'validation' data seprately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining a function to calculate Residual Sum of Squares (RSS). It basically takes difference between two inputed parameter and\n",
    "# returns output as their difference.\n",
    "def RSS_data(prediction,actual):\n",
    "    difference = actual - prediction # It takes difference between actual value and predicted value. Since, actual as well\n",
    "                                    # prediction are in SFrame therefore the difference is calculated corresponding to each entry\n",
    "    square_diff = difference * difference # We are squaring the difference in order to make them all positive\n",
    "    total_diff  = square_diff.sum() # sum up all the values using .sum() function\n",
    "    return(total_diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">id</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">date</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">price</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">bedrooms</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">bathrooms</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_living</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_lot</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">floors</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">waterfront</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7129300520</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-10-13 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">221900.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1180.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5650</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6414100192</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-12-09 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">538000.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.25</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2570.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7242</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5631500400</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-02-25 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">180000.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">770.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2487200875</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-12-09 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">604000.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1960.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1954400510</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-02-18 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">510000.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1680.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8080</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7237550310</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-05-12 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1225000.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5420.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">101930</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1321400060</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-06-27 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">257500.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.25</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1715.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6819</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2008000270</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-01-15 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">291850.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1060.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9711</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2414600126</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-04-15 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">229500.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1780.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7470</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3793500160</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-03-12 00:00:00+00:00</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">323000.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1890.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6560</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">view</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">condition</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">grade</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_above</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_basement</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">yr_built</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">yr_renovated</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">zipcode</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">lat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1180</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1955</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98178</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.51123398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2170</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">400</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1951</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1991</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98125</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.72102274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">770</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1933</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98028</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.73792661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1050</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">910</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1965</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98136</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.52082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1680</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1987</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98074</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.61681228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">11</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3890</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1530</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2001</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98053</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.65611835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1715</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1995</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98003</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.30972002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1060</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1963</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98198</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.40949984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1050</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">730</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1960</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98146</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.51229381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1890</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2003</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98038</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.36840673</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">long</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_living15</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_lot15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.25677536</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1340.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.3188624</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1690.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.23319601</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2720.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.39318505</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1360.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.04490059</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1800.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.00528655</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4760.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">101930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.32704857</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2238.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.31457273</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1650.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.33659507</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1780.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.0308176</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2390.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7570.0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[21613 rows x 21 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tid\tstr\n",
       "\tdate\tdatetime\n",
       "\tprice\tfloat\n",
       "\tbedrooms\tfloat\n",
       "\tbathrooms\tfloat\n",
       "\tsqft_living\tfloat\n",
       "\tsqft_lot\tint\n",
       "\tfloors\tstr\n",
       "\twaterfront\tint\n",
       "\tview\tint\n",
       "\tcondition\tint\n",
       "\tgrade\tint\n",
       "\tsqft_above\tint\n",
       "\tsqft_basement\tint\n",
       "\tyr_built\tint\n",
       "\tyr_renovated\tint\n",
       "\tzipcode\tstr\n",
       "\tlat\tfloat\n",
       "\tlong\tfloat\n",
       "\tsqft_living15\tfloat\n",
       "\tsqft_lot15\tfloat\n",
       "\n",
       "Rows: 21613\n",
       "\n",
       "Data:\n",
       "+------------+---------------------------+-----------+----------+-----------+\n",
       "|     id     |            date           |   price   | bedrooms | bathrooms |\n",
       "+------------+---------------------------+-----------+----------+-----------+\n",
       "| 7129300520 | 2014-10-13 00:00:00+00:00 |  221900.0 |   3.0    |    1.0    |\n",
       "| 6414100192 | 2014-12-09 00:00:00+00:00 |  538000.0 |   3.0    |    2.25   |\n",
       "| 5631500400 | 2015-02-25 00:00:00+00:00 |  180000.0 |   2.0    |    1.0    |\n",
       "| 2487200875 | 2014-12-09 00:00:00+00:00 |  604000.0 |   4.0    |    3.0    |\n",
       "| 1954400510 | 2015-02-18 00:00:00+00:00 |  510000.0 |   3.0    |    2.0    |\n",
       "| 7237550310 | 2014-05-12 00:00:00+00:00 | 1225000.0 |   4.0    |    4.5    |\n",
       "| 1321400060 | 2014-06-27 00:00:00+00:00 |  257500.0 |   3.0    |    2.25   |\n",
       "| 2008000270 | 2015-01-15 00:00:00+00:00 |  291850.0 |   3.0    |    1.5    |\n",
       "| 2414600126 | 2015-04-15 00:00:00+00:00 |  229500.0 |   3.0    |    1.0    |\n",
       "| 3793500160 | 2015-03-12 00:00:00+00:00 |  323000.0 |   3.0    |    2.5    |\n",
       "+------------+---------------------------+-----------+----------+-----------+\n",
       "+-------------+----------+--------+------------+------+-----------+-------+------------+\n",
       "| sqft_living | sqft_lot | floors | waterfront | view | condition | grade | sqft_above |\n",
       "+-------------+----------+--------+------------+------+-----------+-------+------------+\n",
       "|    1180.0   |   5650   |   1    |     0      |  0   |     3     |   7   |    1180    |\n",
       "|    2570.0   |   7242   |   2    |     0      |  0   |     3     |   7   |    2170    |\n",
       "|    770.0    |  10000   |   1    |     0      |  0   |     3     |   6   |    770     |\n",
       "|    1960.0   |   5000   |   1    |     0      |  0   |     5     |   7   |    1050    |\n",
       "|    1680.0   |   8080   |   1    |     0      |  0   |     3     |   8   |    1680    |\n",
       "|    5420.0   |  101930  |   1    |     0      |  0   |     3     |   11  |    3890    |\n",
       "|    1715.0   |   6819   |   2    |     0      |  0   |     3     |   7   |    1715    |\n",
       "|    1060.0   |   9711   |   1    |     0      |  0   |     3     |   7   |    1060    |\n",
       "|    1780.0   |   7470   |   1    |     0      |  0   |     3     |   7   |    1050    |\n",
       "|    1890.0   |   6560   |   2    |     0      |  0   |     3     |   7   |    1890    |\n",
       "+-------------+----------+--------+------------+------+-----------+-------+------------+\n",
       "+---------------+----------+--------------+---------+-------------+\n",
       "| sqft_basement | yr_built | yr_renovated | zipcode |     lat     |\n",
       "+---------------+----------+--------------+---------+-------------+\n",
       "|       0       |   1955   |      0       |  98178  | 47.51123398 |\n",
       "|      400      |   1951   |     1991     |  98125  | 47.72102274 |\n",
       "|       0       |   1933   |      0       |  98028  | 47.73792661 |\n",
       "|      910      |   1965   |      0       |  98136  |   47.52082  |\n",
       "|       0       |   1987   |      0       |  98074  | 47.61681228 |\n",
       "|      1530     |   2001   |      0       |  98053  | 47.65611835 |\n",
       "|       0       |   1995   |      0       |  98003  | 47.30972002 |\n",
       "|       0       |   1963   |      0       |  98198  | 47.40949984 |\n",
       "|      730      |   1960   |      0       |  98146  | 47.51229381 |\n",
       "|       0       |   2003   |      0       |  98038  | 47.36840673 |\n",
       "+---------------+----------+--------------+---------+-------------+\n",
       "+---------------+---------------+-----+\n",
       "|      long     | sqft_living15 | ... |\n",
       "+---------------+---------------+-----+\n",
       "| -122.25677536 |     1340.0    | ... |\n",
       "|  -122.3188624 |     1690.0    | ... |\n",
       "| -122.23319601 |     2720.0    | ... |\n",
       "| -122.39318505 |     1360.0    | ... |\n",
       "| -122.04490059 |     1800.0    | ... |\n",
       "| -122.00528655 |     4760.0    | ... |\n",
       "| -122.32704857 |     2238.0    | ... |\n",
       "| -122.31457273 |     1650.0    | ... |\n",
       "| -122.33659507 |     1780.0    | ... |\n",
       "|  -122.0308176 |     2390.0    | ... |\n",
       "+---------------+---------------+-----+\n",
       "[21613 rows x 21 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring data set in order to find relevant features to be used for modeling\n",
    "sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting all features that are present in the data set in order to use it in linear_regression function\n",
    "features_for_modeling = ['bedrooms','bathrooms',\n",
    "                        'sqft_living','sqft_lot',\n",
    "                        'floors','waterfront', 'view', \n",
    "                        'condition', 'grade','sqft_above',\n",
    "                        'sqft_basement','yr_built', 'yr_renovated',\n",
    "                        'sqft_living15', 'sqft_lot15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Ridge Regression Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function will take following values as input:\n",
    "# K: Number of segments into which data is divided\n",
    "# L2_penalty\n",
    "# Data: The dataset\n",
    "# features_for_modeling: Include all the features that will be used for modeling\n",
    "def k_fold_cross_validation_l2(k, L2_penalty, data,features_for_modeling):\n",
    "\n",
    "    n= len(data) # Variable to calculate the length of data set\n",
    "    Total_Sum= 0 # It will store the total error and therefore initial error is zero\n",
    "    for i in xrange(k):\n",
    "        start = (n*i)/k # Start point of selected Kth frame (As described above)\n",
    "        end = (n*(i+1))/k-1 # Ending point of selected Kth frame (As described above)\n",
    "        validation_set= data[start:end+1] # That data will be used to test the predicted model\n",
    "        training_set= data[0:start].append(data[end+1:n]) # That data set will be used to train and predict the model\n",
    "        model_trained = graphlab.linear_regression.create(training_set, features= features_for_modeling,\n",
    "                                              target='price', l2_penalty=L2_penalty,l1_penalty=0,feature_rescaling= True,\n",
    "                                         validation_set=None,verbose=False) # Training of model\n",
    "        model_prediction = model_trained.predict(validation_set) # validating the model\n",
    "        l2_RSS = RSS_data(model_prediction, validation_set['price']) # Comparing predicted price from model with actual one\n",
    "        Total_Sum = Total_Sum + l2_RSS # Adding new error with existing one\n",
    "        Avg_Sum = Total_Sum/k # Averaging out the sum\n",
    "    return Avg_Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best L2 penalty is:  0.0923670857187\n",
      "The lowest RSS corresponding to best L2 penalty is:  9.0830629956e+13\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x39903c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the above function to predict best model using multiple values of L2 penalty\n",
    "best_l2_penalty = 0 # Initializing\n",
    "lowest_RSS_l2 = 10e20 # Initializing \n",
    "for L2_penalty in np.logspace(-10,10, num=30): # Range of values for which L2 penalty value changes\n",
    "    error_l2 = k_fold_cross_validation_l2(10,L2_penalty,training_and_validation_data,features_for_modeling) # Using the above \n",
    "                                                                                                #function to get the error\n",
    "    if lowest_RSS_l2 > error_l2: # Checking for the lowest error\n",
    "        best_l2_penalty = L2_penalty # If the condition is true then the new best_l2_penalty is from that model\n",
    "        lowest_RSS_l2 = error_l2 # Also setting lowest RSS for that corresponding l2 penalty\n",
    "    plt.xscale('log') # Ploting all values of l2 penalty vs errors\n",
    "    plt.plot(L2_penalty,error_l2,'k.')\n",
    "# Printing the error along with the L2_penalty\n",
    "print \"The best L2 penalty is: \", best_l2_penalty\n",
    "print \"The lowest RSS corresponding to best L2 penalty is: \", lowest_RSS_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Lasso Regression Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will take following values as input:\n",
    "# K: Number of segments into which data is divided\n",
    "# L1_penalty\n",
    "# Data: The dataset\n",
    "# features_for_modeling: Include all the features that will be used for modeling\n",
    "def k_fold_cross_validation_l1(k, L1_penalty, data,features_for_modeling):\n",
    "\n",
    "    n_l1= len(data) # Variable to calculate the length of data set\n",
    "    Total_Sum_l1= 0 # It will store the total error and therefore initial error is zero\n",
    "    for i in xrange(k):\n",
    "        start_l1 = (n_l1*i)/k # Start point of selected Kth frame (As described above)\n",
    "        end_l1 = (n_l1*(i+1))/k-1 # Ending point of selected Kth frame (As described above)\n",
    "        validation_set_l1= data[start_l1:end_l1+1] # That data will be used to test the predicted model\n",
    "        training_set_l1= data[0:start_l1].append(data[end_l1+1:n_l1]) # That data set will be used to train and predict the model\n",
    "        model_trained_l1 = graphlab.linear_regression.create(training_set_l1, features= features_for_modeling,\n",
    "                                              target='price', l2_penalty=0,l1_penalty=L1_penalty,\n",
    "                                         validation_set=None,verbose=False) # Training of model\n",
    "        model_prediction_l1 = model_trained_l1.predict(validation_set_l1) # validating the model\n",
    "        l1_RSS = RSS_data(model_prediction_l1, validation_set_l1['price'])\n",
    "        Total_Sum_l1 = Total_Sum_l1 + l1_RSS\n",
    "        Avg_Sum_l1 = Total_Sum_l1/k # Averaging out the sum\n",
    "    return Avg_Sum_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best L1 penalty is:  1e-10\n",
      "The lowest RSS corresponding to best L1 penalty is:  1.28749907777e+14\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxEgOk7MEaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15d367f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the above function to predict best model using multiple values of L1 penalty\n",
    "best_l1_penalty = 0 # Initializing\n",
    "lowest_RSS_l1 = 10e20 # Initializing\n",
    "for L1_penalty in np.logspace(-10,10, num=30): # Range of values for which L1 penalty value changes\n",
    "    error_l1 = k_fold_cross_validation_l1(10,L1_penalty,training_and_validation_data,features_for_modeling) # Using the above \n",
    "                                                                                                #function to get the error\n",
    "    if lowest_RSS_l1 > error_l1:# Checking for the lowest error\n",
    "        best_l1_penalty = L1_penalty # If the condition is true then the new best_l1_penalty is from that model\n",
    "        lowest_RSS_l1 = error_l1 # Also setting lowest RSS for that corresponding l1 penalty\n",
    "    plt.xscale('log') # Ploting all values of l2 penalty vs errors\n",
    "    plt.plot(L1_penalty,error_l1,'k.')\n",
    "# Printing the error along with the L2_penalty\n",
    "print \"The best L1 penalty is: \", best_l1_penalty\n",
    "print \"The lowest RSS corresponding to best L1 penalty is: \", lowest_RSS_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Elastic Net Regression Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data: The dataset\n",
    "def k_fold_cross_validation_l12(k, L12_penalty,L11_penalty,data,features_for_modeling):\n",
    "\n",
    "    n= len(data) # Variable to calculate the length of data set\n",
    "    Total_Sum_l12= 0 # It will store the total error and therefore initial error is zero\n",
    "    for i in xrange(k):\n",
    "        start_l12 = (n*i)/k # Start point of selected Kth frame (As described above)\n",
    "        end_l12 = (n*(i+1))/k-1 # Ending point of selected Kth frame (As described above)\n",
    "        validation_set_l12= data[start_l12:end_l12+1] # That data will be used to test the predicted model\n",
    "        training_set_l12= data[0:start_l12].append(data[end_l12+1:n]) # That data set will be used to train and predict the model\n",
    "        model_trained_l12 = graphlab.linear_regression.create(training_set_l12, features= features_for_modeling,\n",
    "                                              target='price', l2_penalty=L12_penalty,l1_penalty=L11_penalty,\n",
    "                                         validation_set=None,verbose=False) # Training of model\n",
    "        model_prediction_l12 = model_trained_l12.predict(validation_set_l12) # validating the model\n",
    "        l12_RSS = RSS_data(model_prediction_l12, validation_set_l12['price'])\n",
    "        Total_Sum_l12 = Total_Sum_l12 + l12_RSS\n",
    "        Avg_Sum_l12 = Total_Sum_l12/k # Averaging out the sum\n",
    "    return Avg_Sum_l12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best L1 penalty is:  1e-10\n",
      "The best L2 penalty is:  1e-10\n",
      "The lowest RSS corresponding to best L1/L2 penalty is:  1.28749907777e+14\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEKCAYAAADgl7WbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc0lqgGEuSQ0wzCWpAf8HbnO2A7LlB9oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15f9bb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the above function to predict best model using multiple values of L1 penalty\n",
    "best_l12_penalty = 0 # Initializing\n",
    "lowest_RSS_l12 = 10e20 # Initializing\n",
    "for L11_penalty in np.logspace(-10,1, num=5): # Range of values for which L1 penalty value changes\n",
    "    for L12_penalty in np.logspace(-10,1, num=5): # Range of values for which L2 penalty value changes\n",
    "        error_l12 = k_fold_cross_validation_l12(10,L12_penalty,L11_penalty,training_and_validation_data,features_for_modeling) # Using\n",
    "                                                                                    # the above function to get the error\n",
    "        if lowest_RSS_l12 > error_l12: # Checking for the lowest error\n",
    "            best_l12_penalty = L12_penalty# If the condition is true then the new best_l2_penalty is from that model\n",
    "            best_l11_penalty = L11_penalty# If the condition is true then the new best_l1_penalty is from that model\n",
    "            lowest_RSS_l12 = error_l12# Also setting lowest RSS for that corresponding l1 and l2 penalty\n",
    "        # Since there are three parameters for plotting i.e. L1 Penalty, L2 Penalty, and Error therefore in order\n",
    "        # to draw them we use two different plots as shown below\n",
    "        plt.xscale('log')\n",
    "        plt.plot(L12_penalty,error_l12,'k.') # For L2 Penalty\n",
    "    plt.xscale('log')\n",
    "    plt.plot(L11_penalty,error_l12,'k.') # For L1 Penalty\n",
    "# Printing the error along with the L2_penalty\n",
    "print \"The best L1 penalty is: \", best_l11_penalty\n",
    "print \"The best L2 penalty is: \", best_l12_penalty\n",
    "print \"The lowest RSS corresponding to best L1/L2 penalty is: \", lowest_RSS_l12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with no regularization i.e. without any penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data: The dataset\n",
    "def k_fold_cross_validation_no_penalty(k, no_penalty, data,features_for_modeling):\n",
    "\n",
    "    n= len(data) # Variable to calculate the length of data set\n",
    "    Total_Sum_no= 0 # It will store the total error and therefore initial error is zero\n",
    "    for i in xrange(k):\n",
    "        start_no = (n*i)/k # Start point of selected Kth frame (As described above)\n",
    "        end_no = (n*(i+1))/k-1 # Ending point of selected Kth frame (As described above)\n",
    "        validation_set_no= data[start_no:end_no+1] # That data will be used to test the predicted model\n",
    "        training_set_no= data[0:start_no].append(data[end_no+1:n]) # That data set will be used to train and predict the model\n",
    "        model_trained_no = graphlab.linear_regression.create(training_set_no, features= features_for_modeling,\n",
    "                                              target='price', l2_penalty=0,l1_penalty=0,\n",
    "                                         validation_set=None,verbose=False) # Training of model\n",
    "        model_prediction_no = model_trained_no.predict(validation_set_no) # validating the model\n",
    "        RSS_no = RSS_data(model_prediction_no, validation_set_no['price'])\n",
    "        Total_Sum_no = Total_Sum_no + RSS_no\n",
    "        Avg_Sum_no = Total_Sum_no/k # Averaging out the sum\n",
    "    return Avg_Sum_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of no penalty is:  0\n",
      "RSS value corresponding to no penalty is:  9.08373912816e+13\n"
     ]
    }
   ],
   "source": [
    "best_no_penalty = 0 # Setting best_no_penalty variable to be 0\n",
    "lowest_RSS_no = 10e20 # Initializing\n",
    "error_no = k_fold_cross_validation_no_penalty(10,0,training_and_validation_data,features_for_modeling) # Using the above function \n",
    "                                                                                                #to get the error\n",
    "lowest_RSS_no = error_no # The error of the model \n",
    "print \"The value of no penalty is: \", best_no_penalty\n",
    "print \"RSS value corresponding to no penalty is: \", lowest_RSS_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best L2 Penalty:  0.0923670857187\n",
      "Error corresponding to best L2 penalty:  9.0830629956e+13\n",
      "Best L1 Penalty:  1e-10\n",
      "Error corresponding to best L1 penalty:  1.28749907777e+14\n",
      "Best L1 Penalty and L2 penalty respectively:  1e-10 1e-10\n",
      "Error corresponding to best L1 and L2 penalty:  1.28749907777e+14\n",
      "Value of No penalty:  0\n",
      "Error corresponding to no penalty is:  9.08373912816e+13\n"
     ]
    }
   ],
   "source": [
    "print \"Best L2 Penalty: \", best_l2_penalty\n",
    "print \"Error corresponding to best L2 penalty: \", lowest_RSS_l2\n",
    "print \"Best L1 Penalty: \", best_l1_penalty\n",
    "print \"Error corresponding to best L1 penalty: \", lowest_RSS_l1\n",
    "print \"Best L1 Penalty and L2 penalty respectively: \", best_l11_penalty, best_l12_penalty\n",
    "print \"Error corresponding to best L1 and L2 penalty: \", lowest_RSS_l12\n",
    "print \"Value of No penalty: \", best_no_penalty\n",
    "print \"Error corresponding to no penalty is: \", lowest_RSS_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Dataset\n",
    "### Now the next step is to test the dataset using testing data corresponding to best ridge, lasso and elasticnet \n",
    "### model and check which model can most accurately predict the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS value for testing data corresponding to best L2 Penalty:  1.03138268068e+14\n",
      "RSS value for testing data corresponding to best L1 Penalty:  1.12975857254e+14\n",
      "RSS value for testing data corresponding to best L1,L2 Penalty:  1.48515271857e+14\n",
      "RSS value for testing data corresponding to no Penalty:  1.48515271857e+14\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "# Here we set value of L2 penalty corresponding to best value that we calculated above\n",
    "model_trained_test_l2 = graphlab.linear_regression.create(training_and_validation_data, features= features_for_modeling ,\n",
    "                                             target='price', l2_penalty= best_l2_penalty,l1_penalty=0,feature_rescaling= True,\n",
    "                                        validation_set=None,verbose=False) # Training of model\n",
    "model_trained_l2 = model_trained_test_l2.predict(testing_data) # validating the model\n",
    "RSS_trained_l2 = RSS_data(model_trained_l2, testing_data['price']) # Comparing the values\n",
    "print \"RSS value for testing data corresponding to best L2 Penalty: \", RSS_trained_l2\n",
    "\n",
    "# Lasso Regression\n",
    "# Here we set value of L1 penalty corresponding to best value that we calculated above\n",
    "model_trained_test_l1 = graphlab.linear_regression.create(training_and_validation_data, features= features_for_modeling ,\n",
    "                                             target='price', l2_penalty=0,l1_penalty=best_l2_penalty,max_iterations=100,\n",
    "                                        validation_set=None,verbose=False) # Training of model\n",
    "model_trained_l1 = model_trained_test_l1.predict(testing_data) # validating the model\n",
    "RSS_trained_l1 = RSS_data(model_trained_l1, testing_data['price'])  # Comparing the values\n",
    "print \"RSS value for testing data corresponding to best L1 Penalty: \", RSS_trained_l1\n",
    "\n",
    "# ElasticNet Regression\n",
    "# Here we set value of L1 penalty corresponding to best value that we calculated above\n",
    "model_trained_test_l12 = graphlab.linear_regression.create(training_and_validation_data, features= features_for_modeling ,\n",
    "                                             target='price', l2_penalty=best_l12_penalty,l1_penalty=best_l11_penalty,\n",
    "                                        validation_set=None,verbose=False) # Training of model\n",
    "model_trained_l12 = model_trained_test_l12.predict(testing_data) # validating the model\n",
    "RSS_trained_l12 = RSS_data(model_trained_l12, testing_data['price']) # Comparing the values\n",
    "print \"RSS value for testing data corresponding to best L1,L2 Penalty: \", RSS_trained_l12\n",
    "\n",
    "# No Regularization\n",
    "# Here we set value of L1 and L2 penalty to be zero \n",
    "model_trained_test_no = graphlab.linear_regression.create(training_and_validation_data, features= features_for_modeling ,\n",
    "                                             target='price', l2_penalty=0,l1_penalty=0,max_iterations=100,feature_rescaling= True,\n",
    "                                        validation_set=None,verbose=False) # Training of model\n",
    "model_trained_no = model_trained_test_no.predict(testing_data) # validating the model\n",
    "RSS_trained_no = RSS_data(model_trained_no, testing_data['price'])  # Comparing the values\n",
    "print \"RSS value for testing data corresponding to no Penalty: \", RSS_trained_l12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Adding Features in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are few features in the given data therefore we will add few more features from the existing features in order\n",
    "to increase value of those features that are important in decision making while buyig/selling the house.\n",
    "We will add following features from existing features:\n",
    "sqft_living_sqrt from Sqft_living by taking its square root\n",
    "sqft_lot_sqrt from sqft_lot by taking its square root\n",
    "sq_floors from floors by squaring it\n",
    "sq_bedrooms from bedrooms\n",
    "sq_sqft_basement from sqft_basement by squaring it. \n",
    "Similarly muliple other features are added in it in order to best fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt # Importing log and sqrt from the math library\n",
    "# Here were are adding features to data set by either squaring or taking square root of existing features\n",
    "sales_data['sqft_living_sqrt'] = sales_data['sqft_living'].apply(sqrt)\n",
    "sales_data['sqft_lot_sqrt'] = sales_data['sqft_lot'].apply(sqrt)\n",
    "sales_data['sqft_living15_sqrt'] = sales_data['sqft_living15'].apply(sqrt)\n",
    "sales_data['sqft_lot15_sqrt'] = sales_data['sqft_lot15'].apply(sqrt)\n",
    "sales_data['sqft_above_sqrt'] = sales_data['sqft_above'].apply(sqrt)\n",
    "sales_data['sq_condition'] = sales_data['condition']* sales_data['condition']\n",
    "# Since, 'floors' is defined as type string, \n",
    "# so we'll convert that column to float, before creating a new feature from it.\n",
    "sales_data['floors'] = sales_data['floors'].astype(float) \n",
    "sales_data['sq_floors'] = sales_data['floors']*sales_data['floors']\n",
    "sales_data['sq_yr_renovated'] = sales_data['yr_renovated']*sales_data['yr_renovated']\n",
    "sales_data['sq_yr_built'] = sales_data['yr_built']* sales_data['yr_built']\n",
    "sales_data['sq_bedrooms'] = sales_data['bedrooms']*sales_data['bedrooms']\n",
    "sales_data['cb_bedrooms'] = sales_data['bedrooms']*sales_data['bedrooms']*sales_data['bedrooms'].apply(sqrt)\n",
    "sales_data['sq_bathrooms'] = sales_data['bathrooms']*sales_data['bathrooms']\n",
    "sales_data['cb_bathrooms'] = sales_data['bathrooms']*sales_data['bathrooms']*sales_data['bathrooms']\n",
    "sales_data['sqrt_sqft_basement'] = sales_data['sqft_basement'].apply(sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_all_features= ['bedrooms','bathrooms',\n",
    "                        'sqft_living','sqft_lot',\n",
    "                        'floors','waterfront', 'view', \n",
    "                        'condition', 'grade','sqft_above', 'sq_condition','sqft_above_sqrt',\n",
    "                        'sqft_basement','yr_built', 'yr_renovated',\n",
    "                        'sqft_living15', 'sqft_lot15', 'sq_floors', 'sq_yr_renovated',\n",
    "                         'sqft_living15_sqrt','sqft_living_sqrt','sqft_lot_sqrt',\n",
    "                        'sq_bathrooms','sq_bedrooms','sqrt_sqft_basement', 'cb_bedrooms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating New Training/Validation and Testing data with added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The next step is to divide the data set into training and testing subset.\n",
    "# After reading few articles, it is concluded that generally the best split between training and test subset is 80/20 i.e. \n",
    "# 90 % data should be training while 10 % should be testing.\n",
    "(training_and_validation_data_fe, testing_data_fe) = sales_data.random_split(.9,seed=1) # initial training/test split\n",
    "# as discussed above.\n",
    "# Here, seed=1 is used that will act as a parameter to generate random split for the data set.\n",
    "# Since we will be using cross validation therefore we donot need to split 'training_and_validation_data' into 'training' and\n",
    "# 'validation' data seprately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression with added Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best L2 penalty with added features is:  0.0188739182214\n",
      "The lowest RSS with added features corresponding to best L2 penalty is:  8.09215852421e+13\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2cb7a470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the function to predict best model using multiple values of L2 penalty\n",
    "best_l2_penalty = 0 # Initializing\n",
    "lowest_RSS_l2 = 10e20 # Initializing \n",
    "for L2_penalty in np.logspace(-10,10, num=30): # Range of values for which L2 penalty value changes\n",
    "    error_l2 = k_fold_cross_validation_l2(10,L2_penalty,training_and_validation_data_fe,new_all_features) # Using the above \n",
    "                                                                                                #function to get the error\n",
    "    if lowest_RSS_l2 > error_l2: # Checking for the lowest error\n",
    "        best_l2_penalty = L2_penalty # If the condition is true then the new best_l2_penalty is from that model\n",
    "        lowest_RSS_l2 = error_l2 # Also setting lowest RSS for that corresponding l2 penalty\n",
    "    plt.xscale('log') # Ploting all values of l2 penalty vs errors\n",
    "    plt.plot(L2_penalty,error_l2,'k.')\n",
    "# Printing the error along with the L2_penalty\n",
    "print \"The best L2 penalty with added features is: \", best_l2_penalty\n",
    "print \"The lowest RSS with added features corresponding to best L2 penalty is: \", lowest_RSS_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression with Added Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best L1 penalty with added features is:  1e-10\n",
      "The lowest RSS with added features corresponding to best L1 penalty is:  1.33823131288e+14\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x159cf668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the function to predict best model using multiple values of L1 penalty\n",
    "best_l1_penalty = 0 # Initializing\n",
    "lowest_RSS_l1 = 10e20 # Initializing\n",
    "for L1_penalty in np.logspace(-10,10, num=30): # Range of values for which L1 penalty value changes\n",
    "    error_l1 = k_fold_cross_validation_l1(10,L1_penalty,training_and_validation_data_fe,new_all_features) # Using the above \n",
    "                                                                                                #function to get the error\n",
    "    if lowest_RSS_l1 > error_l1:# Checking for the lowest error\n",
    "        best_l1_penalty = L1_penalty # If the condition is true then the new best_l1_penalty is from that model\n",
    "        lowest_RSS_l1 = error_l1 # Also setting lowest RSS for that corresponding l1 penalty\n",
    "    plt.xscale('log') # Ploting all values of l2 penalty vs errors\n",
    "    plt.plot(L1_penalty,error_l1,'k.')\n",
    "# Printing the error along with the L2_penalty\n",
    "print \"The best L1 penalty with added features is: \", best_l1_penalty\n",
    "print \"The lowest RSS with added features corresponding to best L1 penalty is: \", lowest_RSS_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet Regression with Added Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best L1 penalty with Added Features is:  1e-10\n",
      "The best L2 penalty with Added Features is:  1e-10\n",
      "The lowest RSS with Added Features corresponding to best L1/L2 penalty is:  1.33823131288e+14\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEKCAYAAADgl7WbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15bb4160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the function to predict best model using multiple values of L1 penalty\n",
    "best_l12_penalty = 0 # Initializing\n",
    "lowest_RSS_l12 = 10e20 # Initializing\n",
    "for L11_penalty in np.logspace(-10,1, num=5): # Range of values for which L1 penalty value changes\n",
    "    for L12_penalty in np.logspace(-10,1, num=5): # Range of values for which L2 penalty value changes\n",
    "        error_l12 = k_fold_cross_validation_l12(10,L12_penalty,L11_penalty,training_and_validation_data_fe,new_all_features) # Using\n",
    "                                                                                    # the above function to get the error\n",
    "        if lowest_RSS_l12 > error_l12: # Checking for the lowest error\n",
    "            best_l12_penalty = L12_penalty# If the condition is true then the new best_l2_penalty is from that model\n",
    "            best_l11_penalty = L11_penalty# If the condition is true then the new best_l1_penalty is from that model\n",
    "            lowest_RSS_l12 = error_l12# Also setting lowest RSS for that corresponding l1 and l2 penalty\n",
    "        # Since there are three parameters for plotting i.e. L1 Penalty, L2 Penalty, and Error therefore in order\n",
    "        # to draw them we use two different plots as shown below\n",
    "        plt.xscale('log')\n",
    "        plt.plot(L12_penalty,error_l12,'k.') # For L2 Penalty\n",
    "    plt.xscale('log')\n",
    "    plt.plot(L11_penalty,error_l12,'k.') # For L1 Penalty\n",
    "# Printing the error along with the L2_penalty\n",
    "print \"The best L1 penalty with Added Features is: \", best_l11_penalty\n",
    "print \"The best L2 penalty with Added Features is: \", best_l12_penalty\n",
    "print \"The lowest RSS with Added Features corresponding to best L1/L2 penalty is: \", lowest_RSS_l12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling added features with no regularization i.e. without any penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of no penalty with added features is:  0\n",
      "RSS with added features corresponding to no penalty is:  8.09288926736e+13\n"
     ]
    }
   ],
   "source": [
    "best_no_penalty = 0 # Setting best_no_penalty variable to be 0\n",
    "lowest_RSS_no = 10e20 # Initializing\n",
    "error_no = k_fold_cross_validation_no_penalty(10,0,training_and_validation_data_fe,new_all_features) # Using the above function \n",
    "                                                                                                #to get the error\n",
    "lowest_RSS_no = error_no # The error of the model \n",
    "print \"The value of no penalty with added features is: \", best_no_penalty\n",
    "print \"RSS with added features corresponding to no penalty is: \", lowest_RSS_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best L2 Penalty with added features:  0.0188739182214\n",
      "Error with added features corresponding to best L2 penalty:  8.09215852421e+13\n",
      "Best L1 Penalty with added features:  1e-10\n",
      "Error with added features corresponding to best L1 penalty:  1.33823131288e+14\n",
      "Best L1 Penalty and L2 penalty respectively with added features:  1e-10 1e-10\n",
      "Error with added features corresponding to best L1 and L2 penalty:  1.33823131288e+14\n",
      "Value of No penaltywith added features:  0\n",
      "Error with added features corresponding to no penalty is:  8.09288926736e+13\n"
     ]
    }
   ],
   "source": [
    "print \"Best L2 Penalty with added features: \", best_l2_penalty\n",
    "print \"Error with added features corresponding to best L2 penalty: \", lowest_RSS_l2\n",
    "print \"Best L1 Penalty with added features: \", best_l1_penalty\n",
    "print \"Error with added features corresponding to best L1 penalty: \", lowest_RSS_l1\n",
    "print \"Best L1 Penalty and L2 penalty respectively with added features: \", best_l11_penalty, best_l12_penalty\n",
    "print \"Error with added features corresponding to best L1 and L2 penalty: \", lowest_RSS_l12\n",
    "print \"Value of No penaltywith added features: \", best_no_penalty\n",
    "print \"Error with added features corresponding to no penalty is: \", lowest_RSS_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Dataset with added features\n",
    "### Now the next step is to test the dataset using testing data corresponding to best ridge, lasso and elasticnet\n",
    "### model and check which model can most accurately predict the dataset with added features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS value for testing data with added features corresponding to best L2 Penalty:  9.67981193121e+13\n",
      "RSS value for testing data with added features corresponding to best L1 Penalty:  1.14035730071e+14\n",
      "RSS value for testing data with added features corresponding to best L1,L2 Penalty:  1.55065316576e+14\n",
      "RSS value for testing data with added features corresponding to no Penalty:  1.55065316576e+14\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "# Here we set value of L2 penalty corresponding to best value that we calculated above\n",
    "model_trained_test_l2 = graphlab.linear_regression.create(training_and_validation_data_fe, features= new_all_features,\n",
    "                                             target='price', l2_penalty= best_l2_penalty,l1_penalty=0,feature_rescaling= True,\n",
    "                                        validation_set=None,verbose=False) # Training of model\n",
    "model_trained_l2 = model_trained_test_l2.predict(testing_data_fe) # validating the model\n",
    "RSS_trained_l2 = RSS_data(model_trained_l2, testing_data_fe['price']) # Comparing the values\n",
    "print \"RSS value for testing data with added features corresponding to best L2 Penalty: \", RSS_trained_l2\n",
    "\n",
    "# Lasso Regression\n",
    "# Here we set value of L1 penalty corresponding to best value that we calculated above\n",
    "model_trained_test_l1 = graphlab.linear_regression.create(training_and_validation_data_fe, features= new_all_features,\n",
    "                                             target='price', l2_penalty=0,l1_penalty=best_l2_penalty,max_iterations=100,\n",
    "                                        validation_set=None,verbose=False) # Training of model\n",
    "model_trained_l1 = model_trained_test_l1.predict(testing_data_fe) # validating the model\n",
    "RSS_trained_l1 = RSS_data(model_trained_l1, testing_data_fe['price'])  # Comparing the values\n",
    "print \"RSS value for testing data with added features corresponding to best L1 Penalty: \", RSS_trained_l1\n",
    "\n",
    "# ElasticNet Regression\n",
    "# Here we set value of L1 penalty corresponding to best value that we calculated above\n",
    "model_trained_test_l12 = graphlab.linear_regression.create(training_and_validation_data_fe, features= new_all_features,\n",
    "                                             target='price', l2_penalty=best_l12_penalty,l1_penalty=best_l11_penalty,\n",
    "                                        validation_set=None,verbose=False) # Training of model\n",
    "model_trained_l12 = model_trained_test_l12.predict(testing_data_fe) # validating the model\n",
    "RSS_trained_l12 = RSS_data(model_trained_l12, testing_data_fe['price']) # Comparing the values\n",
    "print \"RSS value for testing data with added features corresponding to best L1,L2 Penalty: \", RSS_trained_l12\n",
    "\n",
    "# No Regularization\n",
    "# Here we set value of L1 and L2 penalty to be zero \n",
    "model_trained_test_no = graphlab.linear_regression.create(training_and_validation_data_fe, features= new_all_features,\n",
    "                                             target='price', l2_penalty=0,l1_penalty=0,max_iterations=100,feature_rescaling= True,\n",
    "                                        validation_set=None,verbose=False) # Training of model\n",
    "model_trained_no = model_trained_test_no.predict(testing_data_fe) # validating the model\n",
    "RSS_trained_no = RSS_data(model_trained_no, testing_data_fe['price'])  # Comparing the values\n",
    "print \"RSS value for testing data with added features corresponding to no Penalty: \", RSS_trained_l12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
